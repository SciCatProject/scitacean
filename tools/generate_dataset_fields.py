# SPDX-License-Identifier: BSD-3-Clause
# Copyright (c) 2022 Scitacean contributors (https://github.com/SciCatProject/scitacean)
# @author Jan-Lukas Wynen

from __future__ import annotations

from dataclasses import dataclass
import re
from typing import Optional
import sys

from pyscicat.model import DerivedDataset, RawDataset

OMIT = (
    "number_of_files",
    "number_of_files_archived",
    "packed_size",
    "size",
    "scientific_metadata",
)


def camel_case_to_snake_case(s):
    return s[0] + re.sub(r"[A-Z]", lambda m: "_" + m[0].lower(), s[1:])


def normalize_derived_name(name):
    try:
        return {"investigator": "investigator", "type": "dataset_type"}[name]
    except KeyError:
        return camel_case_to_snake_case(name)


def normalize_raw_name(name):
    try:
        return {"principalInvestigator": "investigator", "type": "dataset_type"}[name]
    except KeyError:
        return camel_case_to_snake_case(name)


def join_fields():
    fields = {
        normalize_derived_name(field.name): Field.make(
            field, in_derived=field.name, in_raw=None
        )
        for field in DerivedDataset.__fields__.values()
    }
    for field in RawDataset.__fields__.values():
        name = normalize_raw_name(field.name)
        if name in fields:
            fields[name].name_in_raw = field.name
            # Must be optional if either one is optional
            fields[name].optional |= field.allow_none
        else:
            fields[name] = Field.make(field, in_derived=None, in_raw=field.name)

    # Fields present in only one model must be optional here.
    for field in fields.values():
        if not field.name_in_derived or not field.name_in_raw:
            field.optional = True
    return fields


@dataclass
class Field:
    typ: str
    optional: bool
    name_in_derived: Optional[str]
    name_in_raw: Optional[str]

    @classmethod
    def make(cls, pydantic_field, in_derived, in_raw) -> Field:
        # str of types produces, e.g., <class 'str'> which is not a valid
        # type annotation. So use __name__ in those cases but str(outer_typ)
        # for generic types like typing.List[str].
        outer_typ = pydantic_field.outer_type_
        typ = outer_typ.__name__ if isinstance(outer_typ, type) else str(outer_typ)

        return Field(
            typ=typ,
            optional=pydantic_field.allow_none,
            name_in_derived=in_derived,
            name_in_raw=in_raw,
        )

    @property
    def full_typ(self) -> str:
        return f"Optional[{self.typ}]" if self.optional else self.typ


def generate_omitted_arg_list(fields):
    return (",\n" + " " * 8).join(f"{name}: {fields[name].full_typ}" for name in OMIT)


def generate_omitted_assignment():
    return "\n".join(
        f'        mapped[name_mapping["{name}"]] = {name}' for name in OMIT
    )


def generate_name_in_derived_map():
    indent = " " * 6
    return (
        "{\n"
        + ",\n".join(
            indent + f'"{normalize_derived_name(field.name)}": "{field.name}"'
            for field in DerivedDataset.__fields__.values()
        )
        + "}"
    )


def generate_name_in_raw_map():
    indent = " " * 6
    return (
        "{\n"
        + ",\n".join(
            indent + f'"{normalize_raw_name(field.name)}": "{field.name}"'
            for field in RawDataset.__fields__.values()
        )
        + "}"
    )


def generate_field_spec(name, field):
    default = " = None" if field.optional else ""
    return f"{name}: {field.full_typ}{default}"


def generate_fields_spec(fields):
    return "\n".join(
        f"    {generate_field_spec(name, field)}"
        for name, field in sorted(
            sorted(fields.items(), key=lambda t: t[0]), key=lambda t: t[1].optional
        )
        if name not in OMIT
    )


def generate_dataset():
    fields = join_fields()
    src = f"""# This file was generated by tools/generate_dataset_fields.py

import dataclasses
from typing import Any, Dict, Optional, Union
import typing

from pyscicat.model import DatasetType, DerivedDataset, RawDataset

_NAME_IN_DERIVED = {generate_name_in_derived_map()}
_NAME_IN_RAW = {generate_name_in_raw_map()}


@dataclasses.dataclass
class DatasetFields:
{generate_fields_spec(fields)}

    def _map_fields(self, name_mapping, type_name: str) -> Dict[str, Any]:
        mapped = {{}}
        for name, val in filter(
            lambda t: t[1] is not None, dataclasses.asdict(self).items()
        ):
            try:
                mapped[name_mapping[name]] = val
            except KeyError:raise TypeError(
                    f"Field {{name}} is not allowed" f" in {{type_name}} datasets"
                ) from None
        return mapped

    def _map_to_model(
        self,
        {generate_omitted_arg_list(fields)}
    ) -> Union[DerivedDataset, RawDataset]:
        if self.dataset_type == DatasetType.derived:
            name_mapping = _NAME_IN_DERIVED
            type_name = "derived"
            model = DerivedDataset
        else:
            name_mapping = _NAME_IN_RAW
            type_name = "raw"
            model = RawDataset
        mapped = self._map_fields(name_mapping, type_name)
{generate_omitted_assignment()}
        return model(**mapped)

    @staticmethod
    def _find_field_name_for_model_name(s, mapping):
        for scitacean_name, model_name in mapping.items():
            if model_name == s:
                return scitacean_name
        raise ValueError(f"{{s}} is not a valid field name")

    @staticmethod
    def _map_model_to_field_dict(model):
        d = {{
            DatasetFields._find_field_name_for_model_name(
                name,
                _NAME_IN_DERIVED if model.type == DatasetType.derived else _NAME_IN_RAW,
            ): val
            for name, val in model.dict(exclude_none=True).items()
        }}
        for name in ({', '.join(map(lambda s: f'"{s}"', OMIT))}):
            d.pop(name, None)
        return d
"""
    # TODO conversion to model shows camelCase names in model if validation fails
    return src


def main():
    if len(sys.argv) != 2:
        print("Usage: generate_dataset_fields.py OUTFILE")
        sys.exit(1)
    with open(sys.argv[1], "w") as f:
        f.write(generate_dataset())


if __name__ == "__main__":
    main()
