# SPDX-License-Identifier: BSD-3-Clause
# Copyright (c) 2022 Scitacean contributors (https://github.com/SciCatProject/scitacean)
# @author Jan-Lukas Wynen
# flake8: noqa

"""Base dataclass for Dataset."""

import dataclasses
from datetime import datetime, timezone
from typing import Any, Callable, Dict, Generator, List, Literal, Optional, Union

import dateutil.parser

from .file import File
from .model import DatasetLifecycle, DatasetType, DerivedDataset, OrigDatablock, RawDataset, Technique
from .pid import PID


def _apply_default(
    value: Any, default: Any, default_factory: Optional[Callable]
) -> Any:
    if value is not None:
        return value
    if default_factory is not None:
        return default_factory()
    return default


def _parse_datetime(x: Optional[Union[datetime, str]]) -> datetime:
    if isinstance(x, datetime):
        return x
    if isinstance(x, str):
        if x != "now":
            return dateutil.parser.parse(x)
    return datetime.now(tz=timezone.utc)


class HasImmutableModelError(Exception):
    pass


@dataclasses.dataclass
class _OrigDatablock:
    # TODO File objects can be manipulated (download, upload)
    #  need to use `files` as source of truth and amend model
    model: Optional[OrigDatablock] = None
    files: List[File] = dataclasses.field(default_factory=list)

    @property
    def size(self) -> int:
        return sum(file.size for file in self.files)

    def add_files(self, *files: File):
        if self.model is not None:
            raise HasImmutableModelError()
        self.files.extend(files)

    def get_model(self, dataset) -> OrigDatablock:
        if self.model is not None:
            return self.model
        return OrigDatablock(
            size=self.size,
            dataFileList=[file.make_model() for file in self.files],
            datasetId=dataset.pid,
            ownerGroup=dataset.owner_group,
            accessGroups=dataset.access_groups,
            instrumentGroup=dataset.instrument_group,
        )


class DatasetFields:
    @dataclasses.dataclass(frozen=True)
    class Field:
        name: str
        description: str
        read_only: bool
        required_by_derived: bool
        required_by_raw: bool
        type: type
        used_by_derived: bool
        used_by_raw: bool

        def required(self, dataset_type: DatasetType) -> bool:
            return self.required_by_raw if dataset_type == DatasetType.RAW else self.required_by_derived

    _FIELD_SPEC = $field_spec

    def __init__(
        self,
        *,
        type: Union[DatasetType, Literal["derived", "raw"]],
        creation_time: Optional[Union[datetime, str]] = None,
        $field_init_args,
        _orig_datablocks: Optional[List[_OrigDatablock]] = None,
        _pid: Optional[Union[str, PID]] = None,
        _read_only: Optional[Dict[str, Any]] = None,
    ):
        _read_only = _read_only or {}
        self._fields = {
            "creation_time": _parse_datetime(creation_time),
            "history": _apply_default(_read_only.get("history"), None, list),
            "pid": PID.parse(_pid) if isinstance(_pid, str) else _pid,
            "type": DatasetType(type),
$field_dict_construction
        }
        self._orig_datablocks = [] if _orig_datablocks is None else list(_orig_datablocks)

    @property
    def pid(self) -> Optional[PID]:
        """Persistent identifier for datasets."""
        return self._fields["pid"]

    @property
    def creation_time(self) -> datetime:
        return self._fields["creation_time"]

    @creation_time.setter
    def creation_time(self, value: Union[datetime, str]):
        if value is None:
            raise TypeError("Cannot set creation_time to None")
        self._fields["creation_time"] = _parse_datetime(value)

    def _add_orig_datablock(self):
        self._orig_datablocks.append(_OrigDatablock())

$properties

    @classmethod
    def fields(
        cls,
        dataset_type: Optional[Union[DatasetType, Literal["derived", "raw"]]] = None,
        read_only: Optional[bool] = None,
    ) -> Generator[Field, None, None]:
        """Iterator over dataset fields."""
        it = DatasetFields._FIELD_SPEC
        if dataset_type is not None:
            attr = "used_by_derived" if dataset_type == DatasetType.DERIVED else "used_by_raw"
            it = filter(lambda field: getattr(field, attr), it)
        if read_only is not None:
            it = filter(lambda field: field.read_only == read_only, it)
        yield from it

    def __str__(self) -> str:
        args = ", ".join(
            f"{name}={value}"
            for name, value in (
                (field.name, getattr(self, field.name)) for field in self.fields()
            )
            if value is not None
        )
        return f"Dataset({args})"

    def make_dataset_model(self) -> Union[DerivedDataset, RawDataset]:
        if self.type == DatasetType.DERIVED:
            return self._make_derived_model()
        return self._make_raw_model()

$make_derived_model

$make_raw_model

    @classmethod
    def from_models(
        cls,
        *,
        dataset_model: Union[DerivedDataset, RawDataset],
        orig_datablock_models: Optional[List[OrigDatablock]],
    ):
        """Create a new dataset from fully filled in models.

        Parameters
        ----------
        dataset_model:
            Fields, including scientific metadata are filled from this model.
        orig_datablock_models:
            File links are populated from this model.

        Returns
        -------
        :
            A new dataset.
        """
        args = _fields_from_model(dataset_model)
        read_only_args = args.pop('_read_only')
        read_only_args['history'] = dataset_model.history
        return cls(
            creation_time=dataset_model.creationTime,
            _pid=dataset_model.pid,
            _orig_datablocks=_to_internal_orig_datablocks(dataset_model, orig_datablock_models),
            _read_only=read_only_args,
            **args,
        )


def _fields_from_model(model: Union[DerivedDataset, RawDataset]) -> dict:
    return _fields_from_derived_model(model) if isinstance(model, DerivedDataset) else _fields_from_raw_model(model)


def _to_internal_orig_datablocks(
    dataset_model: Union[DerivedDataset, RawDataset],
    orig_datablock_models: Optional[List[OrigDatablock]],
) -> List[_OrigDatablock]:
    return [
        _OrigDatablock(
            model=dblock,
            files=[
                File.from_scicat(file, source_folder=dataset_model.sourceFolder)
                for file in dblock.dataFileList
            ],
        )
        for dblock in orig_datablock_models
    ]


$fields_from_derived_model

$fields_from_raw_model
