{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Uploading datasets\n",
    "\n",
    "Please read [Downloading datasets](./downloading.ipynb) first as it explains the general setup.\n",
    "\n",
    "We connect to SciCat and a file server using a [Client](../generated/classes/scitacean.Client.rst):\n",
    "```python\n",
    "from scitacean import Client\n",
    "from scitacean.transfer.sftp import SFTPFileTransfer\n",
    "client = Client.from_token(url=\"https://scicat.ess.eu/api/v3\",\n",
    "                           token=...,\n",
    "                           file_transfer=SFTPFileTransfer(\n",
    "                               host=\"login.esss.dk\"\n",
    "                           ))\n",
    "```\n",
    "This code is identical to the one used for [downloading](./downloading.ipynb)\n",
    ".\n",
    "As with the downloading guide, we use a fake client instead of the real one shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitacean.testing.docs import setup_fake_client\n",
    "client = setup_fake_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This is especially useful here as datasets cannot be deleted from SciCat by regular users, and we don't want to pollute the database with our test data.\n",
    "\n",
    "First, we need to generate some data to upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"data/witchcraft.dat\")\n",
    "path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with path.open(\"w\") as f:\n",
    "    f.write(\"7.9 13 666\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Create a new dataset\n",
    "\n",
    "With the totally realistic data in hand, we can construct a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scitacean import Dataset\n",
    "\n",
    "dset = Dataset(\n",
    "    name=\"Spellpower of the Three Witches\",\n",
    "    description=\"The spellpower of the maiden, mother, and crone.\",\n",
    "    type=\"raw\",\n",
    "\n",
    "    owner_group=\"wyrdsisters\",\n",
    "    access_groups=[\"witches\"],\n",
    "\n",
    "    owner=\"Nanny Ogg\",\n",
    "    principal_investigator=\"Esme Weatherwax\",\n",
    "    contact_email=\"nogg@wyrd.lancre\",\n",
    "\n",
    "    creation_location=\"lancre/whichhut\",\n",
    "    data_format=\"space-separated\",\n",
    "    source_folder=\"/somewhere/on/remote\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "There are many more fields that can be filled in as needed.\n",
    "See [scitacean.Dataset](../generated/classes/scitacean.Dataset.rst).\n",
    "\n",
    "Some fields require an explanation:\n",
    "\n",
    "- `dataset_type` is either `raw` or `derived`. The main difference is that derived datasets point to one or more input datasets.\n",
    "- `owner_group` and `access_groups` correspond to users/usergroups on the file server and determine who can access the files.\n",
    "\n",
    "Now we can attach our file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dset.add_local_files(\"data/witchcraft.dat\", base_path=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Setting the `base_path` to `\"data\"` means that the file will be uploaded to `source_folder/withcraft.dat` where `source_folder` will be determined by the file transfer.\n",
    "(See below.)\n",
    "If we did not set `base_path`, the file would end up in `source-dir/data/withcraft.dat`.\n",
    "\n",
    "Now, let's inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(list(dset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dset.size  # in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = list(dset.files)[0]\n",
    "print(f\"{file.remote_access_path(dset.source_folder) = }\")\n",
    "print(f\"{file.local_path = }\")\n",
    "print(f\"{file.size = } bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The file has a `local_path` but no `remote_access_path` which means that it exists on the local file system (where we put it earlier) but not on the remote file server accessible by SciCat.\n",
    "The location can also be queried using `file.is_on_local` and `file.is_on_remote`.\n",
    "\n",
    "Likewise, the dataset only exists in memory on our local machine and not on SciCat.\n",
    "Nothing has been uploaded yet.\n",
    "So we can freely modify the dataset or bail out by deleting the Python object if we need to.\n",
    "\n",
    "## Upload the dataset\n",
    "\n",
    "Once the dataset is ready, we can upload it using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finalized = client.upload_new_dataset_now(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>WARNING:</b>\n",
    "\n",
    "This action cannot be undone by a regular user!\n",
    "Contact an admin if you uploaded a dataset accidentally.\n",
    "\n",
    "</div>\n",
    "\n",
    "[scitacean.Client.upload_new_dataset_now](../generated/classes/scitacean.Client.rst#scitacean.Client.upload_new_dataset_now) uploads the dataset (i.e. metadata) to SciCat and the files to the file server.\n",
    "And it does so in such a way that it always creates a new dataset and new files without overwriting any existing (meta) data.\n",
    "\n",
    "It returns a new dataset that is a copy of the input with some updated information generated by SciCat and the file transfer.\n",
    "For example, it has been assigned a new ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finalized.pid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "And the remote access path of our file has been set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(finalized.files)[0].remote_access_path(finalized.source_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Location of uploaded files\n",
    "\n",
    "All files associated with a dataset will be uploaded to the same folder.\n",
    "This folder may be at the path we specify when making the dataset, i.e. `dset.source_folder`.\n",
    "However, the folder is ultimately determined by the file transfer (in this case SFTPFileTransfer`) and it may choose to override the `source_folder` that we set.\n",
    "In this example, since we don't tell the file transfer otherwise, it respects `dset.source_folder` and uploads the files to that location.\n",
    "See the [File transfer](../reference/index.rst#file-transfer) reference for information how to control this behavior.\n",
    "The reason for this is that facilities may have a specific structure on their file server and Scitacean's file transfers can be used to enforce that.\n",
    "\n",
    "In any case, we can find out where files were uploaded by inspecting the finalized dataset that was returned by `client.upload_new_dataset_now`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finalized.source_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Or by looking at each file individually as shown in the section above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Attaching images to datasets\n",
    "\n",
    "It is possible to attach *small* images to datasets.\n",
    "In SciCat, this is done by creating 'attachment' objects which contain the image.\n",
    "Scitacean handles those via the `attachments` property of `Dataset`.\n",
    "For our locally created dataset, the property is an empty list and we can add an attachment like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitacean import Attachment, Thumbnail\n",
    "\n",
    "dset.attachments.append(\n",
    "    Attachment(\n",
    "        caption=\"Scitacean logo\",\n",
    "        owner_group=dset.owner_group,\n",
    "        thumbnail=Thumbnail.load_file(\"./logo.png\"),\n",
    "    )\n",
    ")\n",
    "dset.attachments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "We used `Thumbnail.load_file` because it properly encodes the file for SciCat.\n",
    "\n",
    "When we then upload the dataset, the client automatically uploads all attachments as well.\n",
    "Note that this creates a new dataset in SciCat.\n",
    "If you want to add attachments to an existing dataset after upload, you need to use the lower-level API through `client.scicat.create_attachment_for_dataset` or the web interface directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized = client.upload_new_dataset_now(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "In order to download the attachments again, we can pass `attachments=True` when downloading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = client.get_dataset(finalized.pid, attachments=True)\n",
    "downloaded.attachments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is hidden.\n",
    "# It should remove *only* files and directories created by this notebook.\n",
    "import shutil\n",
    "shutil.rmtree(\"data\", ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
